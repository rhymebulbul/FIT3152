---
urlcolor: blue
output: pdf_document
---
# FIT3152 Data analytics

## Assignment 3

**Name:** Rhyme Bulbul

**Student ID:** 31865224

**AI statement:** 



## Task 1
I gathered a collection of 19 text documents from different sources that covered a range of themes for this task. Blogs, news stories, movie reviews, and more are included in these publications. The Appendix contains the list of references for these documents.

Text files were created by copying and pasting the document contents.


## Task 2
Task 1 already had the document's contents pasted into text files. The text files were assembled into the `text` folder within the working directory in order to generate the corpus. Next, the code that follows is executed. It installs and imports the necessary libraries, sets the seed and uses the `Corpus()` function from the `tm` package to construct the corpus.

```{r message = FALSE}
rm(list = ls())
set.seed(31865224)
#install.packages("tm")
library(tm)
#install.packages("cluster")
library(cluster)
#install.packages("igraph")
library(igraph)

cname <- file.path(".", "text")
docs <- Corpus(DirSource((cname)))
list.files("text")
```

Documents are named based on the topic, suffixed by a number. Such as, `linux01.txt` is the first text document on linux systems, followed by `linux02.txt` the second text document on the same topic, and so fourth.


## Task 3

We start by text transforming the corpus, meanwhile replacing dashes and line breaks with spaces for consistency, removing numbers, punctuation, converting all characters to lowercase, and removing any extra white spaces. In addition, we also remove English stopwords before finally stemming all words for consistency. This is required as we don't want these characters creating an unwanted bias in our data, as it would be harder to work with, as well as inaccurate.

```{r}
to_space <- content_transformer(function(x, pattern) gsub(pattern, " ", x))
docs <- tm_map(docs, to_space, "-")
docs <- tm_map(docs, to_space, "\n")
docs <- tm_map(docs, removeNumbers)
docs <- tm_map(docs, removePunctuation)
docs <- tm_map(docs, content_transformer(tolower))
docs <- tm_map(docs, stripWhitespace)
docs <- tm_map(docs, removeWords, stopwords("english"))
docs <- tm_map(docs, stemDocument, language = "english")
```

With our unwanted terms removed, and desired keywords preserverd, the corpus is now ready to create a document term matrix from.

```{r}
dtm <- DocumentTermMatrix(docs)
```

Let's analyse the attributes of the document term matrix by inspecting a sample of 20 from it's head and tail of most and least frequent terms in alphabetical order.

```{r}
inspect(dtm)
```

```{r}
freq <- colSums(as.matrix(dtm))
freq[head(order(freq), 20)]
```

```{r}
freq[tail(order(freq), 20)]
```

With 6062 terms, or as we call it, tokens; the DTM is highly sparse at 88%. Interestingly, the least occurring tokens seem to only appear once, while the most frequent token is `android`, occurring almost 500 times, although it is only expected to be used in 3 documents, pointing to it's sparsity.

This leads us to the removal of sparse tokens from the document term matrix. This time we set the sparsity to 0.7 as it gives us the best mix of efficiency, reliability, and observability.

<!-- The next step is to remove sparse terms from the DTM. The maximal allowed sparsity, `sparse`, is set to 0.65, which gives a DTM with 54% sparsity and 32 tokens. A DTM closer to the guideline with 51% sparsity and 23 tokens can be obtained by setting `sparse` to 0.6, but through my analysis I observed that the 32-token DTM gives a better cluster dendrogram and network graph. **I also discovered that setting the sparsity even higher further improves the clustering, but I avoided this due to efficiency issues and poor readability of graphs.** -->

```{r}
dtms <- removeSparseTerms(dtm, 0.7)
inspect(dtms)
freqs <- colSums(as.matrix(dtms))
freqs[head(order(freqs), 20)]
freqs[tail(order(freqs), 20)]
```

This time round, the least frequent tokens are `exact`, `speed`, `pass` and `care` while the most frequent is `use` with 259 uses. The Document term matrix in it's full length can be found attached in the appendix.


## Task 4






















































## Appendix


## References

Wikimedia Foundation. (2024, May 14). Ubuntu. Wikipedia. https://en.wikipedia.org/wiki/Ubuntu 

Wikimedia Foundation. (2024c, May 18). Linux kernel. Wikipedia. https://en.wikipedia.org/wiki/Linux_kernel 

Wikimedia Foundation. (2024a, April 5). Lineageos. Wikipedia. https://en.wikipedia.org/wiki/LineageOS 

Wikimedia Foundation. (2024b, May 7). Android (Operating System). Wikipedia. https://en.wikipedia.org/wiki/Android_(operating_system) 

Encyclopædia Britannica, inc. (2024, May 14). Australia. Encyclopædia Britannica. https://www.britannica.com/place/Australia 

Goode, L. (2024, May 14). It’s the end of google search as we know it. Wired. https://www.wired.com/story/google-io-end-of-google-search/ 

IMDb.com. (2003, June 6). 2 fast 2 furious. IMDb. https://www.imdb.com/title/tt0322259/?ref_=nv_sr_srsg_0_tt_7_nm_1_q_2%2520fast 

IMDb.com. (2009, April 3). Fast & Furious. IMDb. https://www.imdb.com/title/tt1013752/?ref_=nv_sr_srsg_1_tt_7_nm_0_q_fast%2520and%2520fur 

IMDb.com. (2003b, July 9). Pirates of the Caribbean: The curse of the black pearl. IMDb. https://www.imdb.com/title/tt0325980/?ref_=nv_sr_srsg_0_tt_8_nm_0_q_pirates 

IMDb.com. (2017, May 26). Pirates of the caribbean: Dead men tell no tales. IMDb. https://www.imdb.com/title/tt1790809/?ref_=nv_sr_srsg_3_tt_8_nm_0_q_pirates 

IMDb.com. (2014, October 24). John Wick. IMDb. https://www.imdb.com/title/tt2911666/?ref_=nv_sr_srsg_1_tt_7_nm_1_q_jon%2520wick 

IMDb.com. (1996, May 22). Mission: Impossible. IMDb. https://www.imdb.com/title/tt0117060/?ref_=nv_sr_srsg_0_tt_8_nm_0_q_mission 

IMDb.com. (2016, February 12). Deadpool. IMDb. https://www.imdb.com/title/tt1431045/?ref_=nv_sr_srsg_3_tt_6_nm_2_q_deadpool 

IMDb.com. (1984, October 26). The terminator. IMDb. https://www.imdb.com/title/tt0088247/?ref_=nv_sr_srsg_0_tt_8_nm_0_q_terminator 

IMDb.com. (1977, May 25). Star wars: Episode IV - A new hope. IMDb. https://www.imdb.com/title/tt0076759/?ref_=nv_sr_srsg_4_tt_7_nm_0_q_star%2520wars 

IMDb.com. (2004, May 19). Shrek 2. IMDb. https://www.imdb.com/title/tt0298148/?ref_=nv_sr_srsg_0_tt_8_nm_0_q_shrek%25202 

IMDb.com. (2006, October 20). The prestige. IMDb. https://www.imdb.com/title/tt0482571/?ref_=nv_sr_srsg_0_tt_8_nm_0_q_prestige 

IMDb.com. (2013, December 25). The wolf of wall street. IMDb. https://www.imdb.com/title/tt0993846/?ref_=nm_flmg_t_38_prd 

IMDb.com. (2002, December 25). Catch me if you can. IMDb. https://www.imdb.com/title/tt0264464/?ref_=nv_sr_srsg_0_tt_8_nm_0_q_catch%2520me 




